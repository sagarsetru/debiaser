{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA (downloaded document corpus) for 'debiaser' data product\n",
    "#### Sagar Setru, September 21th, 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Brief description using CoNVO framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context\n",
    "\n",
    "Some people are eager to get news from outside of their echo chamber. However, they do not know where to go outside of their echo chambers, and may also have some activation energy when it comes to seeking information from other sources. In the meantime, most newsfeeds only push you content that you agree with. You end up in an echo chamber, but may not have ever wanted to be in one in the first place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need\n",
    "\n",
    "A way to find news articles from different yet reliable media sources."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vision\n",
    "\n",
    "Debiaser, a data product (maybe Chrome plug-in?) that will recommend news articles similar in topic to the one currently being read, but from several pre-curated and reliable news media organizations across the political spectrum, for example, following the \"media bias chart\" here https://www.adfontesmedia.com/ or the \"media bias ratings\" here: https://www.allsides.com/media-bias/media-bias-ratings. The app will determine the main topics of the text of a news article, and then show links to similar articles from other news organizations.\n",
    "\n",
    "The product will generate topics for a given document via latent Dirichlet allocation (LDA) and then search news websites for the topic words generated.\n",
    "\n",
    "Caveats: Many of these articles may be behind paywalls. News aggregators already basically do this. How different is this than just searching Google using the title of an article?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outcome\n",
    "\n",
    "People who are motivated to engage in content outside of their echo chambers have a tool that enables them to quickly find news similar to what they are currently reading, but from a variety of news organizations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing single document lda on these articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conda environment:\n",
      "debiaser\n"
     ]
    }
   ],
   "source": [
    "# make sure I'm in the right environment (should be 'debiaser')\n",
    "import os\n",
    "print('Conda environment:')\n",
    "print(os.environ['CONDA_DEFAULT_ENV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "\n",
    "import json\n",
    "\n",
    "# NLP Packages\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import LdaModel\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "# to break articles up into sentences\n",
    "from nltk import tokenize\n",
    "\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "from text_processing_functions import process_all_articles\n",
    "from text_processing_functions import remove_stopwords\n",
    "from text_processing_functions import get_simple_corpus_dictionary_bow\n",
    "from text_processing_functions import entity_recognizer\n",
    "from text_processing_functions import get_topic_words_mean_std_prob_frequency\n",
    "from text_processing_functions import sort_topics_mean_frequency\n",
    "print('DONE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sagarsetru/anaconda3/envs/debiaser/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3146: DtypeWarning: Columns (12,13) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>index.1</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>content</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>publication</th>\n",
       "      <th>category</th>\n",
       "      <th>digital</th>\n",
       "      <th>section</th>\n",
       "      <th>url</th>\n",
       "      <th>article_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Agent Cooper in Twin Peaks is the audience: on...</td>\n",
       "      <td>\\nTasha Robinson\\n</td>\n",
       "      <td>2017-05-31</td>\n",
       "      <td>And never more so than in Showtime’s new...</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Verge</td>\n",
       "      <td>Longform</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>AI, the humanity!</td>\n",
       "      <td>\\nSam Byford\\n</td>\n",
       "      <td>2017-05-30</td>\n",
       "      <td>AlphaGo’s victory isn’t a defeat for hum...</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Verge</td>\n",
       "      <td>Longform</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>The Viral Machine</td>\n",
       "      <td>\\nKaitlyn Tiffany\\n</td>\n",
       "      <td>2017-05-25</td>\n",
       "      <td>Super Deluxe built a weird internet empi...</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Verge</td>\n",
       "      <td>Longform</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>How Anker is beating Apple and Samsung at thei...</td>\n",
       "      <td>\\nNick Statt\\n</td>\n",
       "      <td>2017-05-22</td>\n",
       "      <td>Steven Yang quit his job at Google in th...</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Verge</td>\n",
       "      <td>Longform</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>Tour Black Panther’s reimagined homeland with ...</td>\n",
       "      <td>\\nKwame Opam\\n</td>\n",
       "      <td>2017-05-15</td>\n",
       "      <td>Ahead of Black Panther’s 2018 theatrical...</td>\n",
       "      <td>2017.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Verge</td>\n",
       "      <td>Longform</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  index.1  id                                              title  \\\n",
       "0      0        0   1  Agent Cooper in Twin Peaks is the audience: on...   \n",
       "1      1        1   2                                  AI, the humanity!   \n",
       "2      2        2   3                                  The Viral Machine   \n",
       "3      3        3   4  How Anker is beating Apple and Samsung at thei...   \n",
       "4      4        4   5  Tour Black Panther’s reimagined homeland with ...   \n",
       "\n",
       "                author        date  \\\n",
       "0   \\nTasha Robinson\\n  2017-05-31   \n",
       "1       \\nSam Byford\\n  2017-05-30   \n",
       "2  \\nKaitlyn Tiffany\\n  2017-05-25   \n",
       "3       \\nNick Statt\\n  2017-05-22   \n",
       "4       \\nKwame Opam\\n  2017-05-15   \n",
       "\n",
       "                                             content    year  month  \\\n",
       "0        And never more so than in Showtime’s new...  2017.0    5.0   \n",
       "1        AlphaGo’s victory isn’t a defeat for hum...  2017.0    5.0   \n",
       "2        Super Deluxe built a weird internet empi...  2017.0    5.0   \n",
       "3        Steven Yang quit his job at Google in th...  2017.0    5.0   \n",
       "4        Ahead of Black Panther’s 2018 theatrical...  2017.0    5.0   \n",
       "\n",
       "  publication  category  digital section  url  article_length  \n",
       "0       Verge  Longform      1.0     NaN  NaN            2121  \n",
       "1       Verge  Longform      1.0     NaN  NaN            1948  \n",
       "2       Verge  Longform      1.0     NaN  NaN            3011  \n",
       "3       Verge  Longform      1.0     NaN  NaN            3281  \n",
       "4       Verge  Longform      1.0     NaN  NaN             239  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_news_df = pd.read_csv('./all_the_news/all_news_df_processed.csv')\n",
    "all_news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stop_words_csv_to_list(full_file_name):\n",
    "    \"\"\"fxn that loads stop words list downloaded from git repo called 'news-stopwords'\"\"\"\n",
    "    \n",
    "    stop_words = pd.read_csv(full_file_name)\n",
    "\n",
    "    stop_words = stop_words['term']\n",
    "\n",
    "    stop_words = [word for word in stop_words]\n",
    "    \n",
    "    return stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lda_top_topic_words(lda_topics,num_topic,unique_topic_words,n_topic_words):\n",
    "    \"\"\"\n",
    "    fxn for algorithm to return the top topic words\n",
    "    algo varies based on:\n",
    "    1) whether only unique words are wanted, and\n",
    "    2) whether there is 1 or more topics\n",
    "    \"\"\"\n",
    "    \n",
    "    # string is for final search string\n",
    "    lda_top_topic_words_string = ''\n",
    "\n",
    "    # list is for checking previous words\n",
    "    lda_top_topic_words_list = []\n",
    "\n",
    "    # if generating more than 1 topic\n",
    "    if num_topic > 1:\n",
    "\n",
    "        # if you're okay with topic words repeating (often happens..)\n",
    "        if not unique_topic_words:\n",
    "\n",
    "            for topic in lda_topics:\n",
    "\n",
    "                # get the list of topics\n",
    "                topic_words = topic[1]\n",
    "\n",
    "                lda_top_topic_words_string += ' '+topic_words[0][0]\n",
    "\n",
    "                lda_top_topic_words_list.append(topic_words[0][0])\n",
    "\n",
    "        # don't reuse a word if it has already been used\n",
    "        else:\n",
    "\n",
    "            # loop through each list of generated topics\n",
    "            for topic in lda_topics:\n",
    "\n",
    "                # set word added to 0\n",
    "                word_added = 0\n",
    "\n",
    "                # get the list of topics\n",
    "                topic_words = topic[1]\n",
    "\n",
    "                # loop through words in topic\n",
    "                # add as search term only if they aren't already search terms\n",
    "                for i in range(len(topic_words)):\n",
    "\n",
    "                    # if the current word in topic is not in list of search terms\n",
    "                    if topic_words[i][0] not in lda_top_topic_words_list:\n",
    "\n",
    "                        # add this word to list of topic/search terms\n",
    "                        lda_top_topic_words_list.append(topic_words[i][0])\n",
    "\n",
    "                        # also update the string for the search terms\n",
    "                        lda_top_topic_words_string += ' '+topic_words[i][0]\n",
    "\n",
    "                        # update word added\n",
    "                        word_added = 1\n",
    "                        break\n",
    "\n",
    "                # if no word was added because all supporting words in topic are already\n",
    "                # search terms, then just add the highest prob/first word in topic\n",
    "                if word_added == 0:\n",
    "                    # if every word in this topic is already a search term,\n",
    "                    # just add the first most probable word and leave the while loop\n",
    "                    lda_top_topic_words_list.append(topic_words[0][0])\n",
    "                    lda_top_topic_words_string += ' '+topic_words[0][0]\n",
    "\n",
    "    else:\n",
    "\n",
    "        for topic in lda_topics:\n",
    "\n",
    "            # get the list of topic words\n",
    "            topic_words = topic[1]\n",
    "\n",
    "            # loop through these words and get the top n number\n",
    "            counter = -1\n",
    "            for topic_word in topic_words:\n",
    "\n",
    "                counter += 1\n",
    "\n",
    "                if counter < n_topic_words:\n",
    "\n",
    "                    lda_top_topic_words_string += ' '+topic_word[0]\n",
    "                    lda_top_topic_words_list.append(topic_word[0])\n",
    "                    \n",
    "    return lda_top_topic_words_string, lda_top_topic_words_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_topic_word_probs(lda_topics,n_topic_words_single_topic_analysis):\n",
    "    \"\"\"\n",
    "    fxn for algorithm to return the top topic words\n",
    "    algo varies based on:\n",
    "    1) whether only unique words are wanted, and\n",
    "    2) whether there is 1 or more topics\n",
    "    \n",
    "                \n",
    "    if one topic, just take top word in each generated topic\n",
    "    else, if unique_topic_words, get top word in each topic that is unique,\n",
    "          else, just get top word in each topic even if it isn't unique\n",
    "    \n",
    "    parameters\n",
    "    ----------\n",
    "    lda_topics - topic output from lda model\n",
    "    num_topic - how many lda topics were generated\n",
    "    unique_topic_words - whether to all repeating words as search terms\n",
    "    n_topic_words - how many topic words to use as search terms\n",
    "    \n",
    "    outputs\n",
    "    -------\n",
    "    list and string of search/topic words\n",
    "    \"\"\"\n",
    "\n",
    "    # generate empty vector for probs associated with words in topic\n",
    "    lda_topic_word_probs = np.zeros((n_topic_words_single_topic_analysis,1))\n",
    "\n",
    "    # set default to nan in case any probs eval to 0..\n",
    "    lda_topic_word_probs[:] = np.nan\n",
    "\n",
    "    for topic in lda_topics:\n",
    "\n",
    "        # get the list of topic words and probs\n",
    "        topic_words = topic[1]\n",
    "\n",
    "        # loop through these words and get the associated probabilities\n",
    "        for ind, topic_word in enumerate(topic_words):\n",
    "\n",
    "            # add probability to prob vector\n",
    "            lda_topic_word_probs[ind] = topic_word[1]\n",
    "            \n",
    "    return lda_topic_word_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_word_frequencies(article_processed_whole,n_topic_words):\n",
    "    \"\"\"\n",
    "    fxn that does simple counting of word frequency.\n",
    "    Goal is to have some baseline for how single doc LDA approach \n",
    "    compares to just counting most common words.\n",
    "    \"\"\"\n",
    "    \n",
    "    # dictionary of word counts\n",
    "    word_dict_count = {}\n",
    "\n",
    "    for word in article_processed_whole[0]:\n",
    "\n",
    "        if word in word_dict_count.keys():\n",
    "\n",
    "            word_dict_count[word] += 1\n",
    "\n",
    "        else:\n",
    "\n",
    "            word_dict_count[word] = 1\n",
    "\n",
    "    # make list for word counts\n",
    "    word_counts = []\n",
    "\n",
    "    # loop through dictionary\n",
    "    for key, value in word_dict_count.items():\n",
    "        word_counts.append(value)\n",
    "    \n",
    "    # get unique values of word counts\n",
    "    word_counts = list(set(word_counts))\n",
    "\n",
    "    # sort counts from high to low \n",
    "    word_counts = sorted(word_counts, reverse=True)\n",
    "\n",
    "    # keep top 5 word counts\n",
    "    word_counts_top = word_counts[0:n_topic_words]\n",
    "\n",
    "    # list for most common words\n",
    "    most_common_words_list = []\n",
    "    most_common_words_string = ''\n",
    "\n",
    "    # loop through dictionary\n",
    "    for key, value in word_dict_count.items():\n",
    "\n",
    "        # if value of this word is one of the top ones, add this word for list of common words\n",
    "        if value in word_counts_top:\n",
    "            most_common_words_list.append(key)\n",
    "            most_common_words_string += ' '+key\n",
    "            \n",
    "    return word_dict_count, word_counts_top, most_common_words_list, most_common_words_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_jaccard_sim(list1, list2): \n",
    "    \"\"\"\n",
    "    fxn calculates jaccard sim between two lists of words\n",
    "    from https://towardsdatascience.com/overview-of-text-similarity-metrics-3397c4601f50\n",
    "    \"\"\"\n",
    "    a = set(list1) \n",
    "    b = set(list2)\n",
    "    \n",
    "    c = a.intersection(b)\n",
    "    \n",
    "    return float(len(c)) / (len(a) + len(b) - len(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cosine_similarity(bow_vec1,bow_vec2):\n",
    "    \"\"\"\n",
    "    fxn calculates the bag of words similarity between two word vectors\n",
    "    \"\"\"\n",
    "    \n",
    "    # get the words in each vector and their lengths in a dictionary\n",
    "    vec1_words_dict = {}\n",
    "    vec2_words_dict = {}\n",
    "    \n",
    "    # get just the words\n",
    "    vec1_words = []\n",
    "    vec2_words = []\n",
    "    \n",
    "    # get just the values\n",
    "    vec1_vals = np.zeros((len(bow_vec1)))\n",
    "    vec2_vals = np.zeros((len(bow_vec2)))\n",
    "    \n",
    "    # populate dictionary and lists\n",
    "    for ind, val in enumerate(bow_vec1):\n",
    "\n",
    "        vec1_words_dict[val[0]] = val[1]\n",
    "        vec1_words.append(val[0])\n",
    "        vec1_vals[ind] = val[1]\n",
    "    \n",
    "    # populate dictionary and lists\n",
    "    for ind, val in enumerate(bow_vec2):\n",
    "        \n",
    "        vec2_words_dict[val[0]] = val[1]\n",
    "        vec2_words.append(val[0])\n",
    "        vec2_vals[ind] = val[1]\n",
    "        \n",
    "    # get norms of each vector\n",
    "    norm_vec1 = np.linalg.norm(vec1_vals)\n",
    "    norm_vec2 = np.linalg.norm(vec2_vals)\n",
    "    \n",
    "    # get the list of all the words\n",
    "    all_words = list(set().union(vec1_words,vec2_words))\n",
    "    \n",
    "    # loop through words, update dictionaries if word is not in original vector\n",
    "    for word in all_words:\n",
    "        \n",
    "        if word not in vec1_words:\n",
    "            \n",
    "            vec1_words_dict[word] = 0\n",
    "            \n",
    "        if word not in vec2_words:\n",
    "            \n",
    "            vec2_words_dict[word] = 0\n",
    "       \n",
    "    # initialize float for final dot product\n",
    "    dot_product = 0.0\n",
    "    \n",
    "    # loop through words\n",
    "    for word in vec1_words_dict.keys():\n",
    "        \n",
    "        vec1_val = vec1_words_dict[word]\n",
    "        vec2_val = vec2_words_dict[word]\n",
    "        \n",
    "        dot_product += (vec1_val * vec2_val)\n",
    "    \n",
    "    cosine_sim = dot_product/(norm_vec1*norm_vec2)\n",
    "    \n",
    "    return cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose list of stop words\n",
    "\n",
    "# choose whether 1k, 10k, 100k, or nltk\n",
    "which_stop_words = '1k'\n",
    "# which_stop_words = '10k'\n",
    "# which_stop_words = '100k'\n",
    "# which_stop_words = 'nltk'\n",
    "\n",
    "stop_words_path = '/Users/sagarsetru/Documents/post PhD positions search/insightDataScience/project/debiaser/stop_words_db/news-stopwords-master/'\n",
    "\n",
    "\n",
    "if which_stop_words == '1k':\n",
    "    \n",
    "    # doing 1k words list\n",
    "    stop_words_file_name = 'sw1k.csv'\n",
    "    \n",
    "    # make full file name\n",
    "    stop_words_full_file_name = stop_words_path+stop_words_file_name\n",
    "    \n",
    "    # get list of stop words\n",
    "    stop_words = load_stop_words_csv_to_list(stop_words_full_file_name)\n",
    "    \n",
    "elif which_stop_words == '10k':\n",
    "    \n",
    "    # doing 10k words list\n",
    "    stop_words_file_name = 'sw10k.csv'\n",
    "\n",
    "    # make full file name\n",
    "    stop_words_full_file_name = stop_words_path+stop_words_file_name\n",
    "    \n",
    "    # get list of stop words\n",
    "    stop_words = load_stop_words_csv_to_list(stop_words_full_file_name)\n",
    "\n",
    "elif which_stop_words == '100k':\n",
    "    \n",
    "    # doing 100k\n",
    "    stop_words_file_name = 'sw100k.csv'  \n",
    "    \n",
    "    # get full file name\n",
    "    stop_words_full_file_name = stop_words_path+stop_words_file_name\n",
    "    \n",
    "    # get list of stop words\n",
    "    stop_words = load_stop_words_csv_to_list(stop_words_full_file_name)\n",
    "\n",
    "\n",
    "elif which_stop_words == 'nltk':\n",
    "    # import from nltk\n",
    "    from nltk.corpus import stopwords\n",
    "    \n",
    "    stop_words = stopwords.words('english')\n",
    "    \n",
    "else:\n",
    "    print('Select proper variable name for \"which_stop_words\"')\n",
    "    \n",
    "# adding custom words\n",
    "stop_words.append('said')\n",
    "stop_words.append('youre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a random sampling of these articles for testing single document lda\n",
    "\n",
    "# number of times to draw a bootstrap sampling\n",
    "n_bootstrap_samples = 1\n",
    "\n",
    "# number of articles to draw per sampling\n",
    "n_articles_per_sample = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_df_random_subset = all_news_df.sample(n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Hillary Clinton’s claim at a fundraiser that half of Donald Trump’s supporters fit into a “basket of deplorables” prompted a swift and negative reaction Saturday from Republicans, including denunciations and calls for her to apologize. The comments echoed an accusation that Clinton had levied previously — that Trump appeals to and amplifies racist, xenophobic and anti-Semitic viewpoints. But Clinton triggered a fresh controversy by claiming that “half” of Trump’s supporters fit that description. At a key moment in the campaign, when both candidates are trying to sharpen their focus for the final, post-Labor Day sprint, Clinton’s remarks took attention from Trump’s spate of gaffes last week and also from her own effort to turn the public’s attention to her qualifications for office and vision for the nation. “You know, to just be grossly generalistic, you could put half of Trump’s supporters into what I call the ‘basket of deplorables.’ Right?” Clinton said to applause and laughter from supporters at the LGBT for Hillary fundraiser Friday night in New York that also featured a performance by Barbra Streisand. “The racist, sexist, homophobic, xenophobic, Islamophobic — you name it.” She continued: “He has given voice to their websites that used to only have 11,000 people — now have 11 million. He tweets and retweets their offensive, hateful, mean-spirited rhetoric.     Republican vice presidential nominee Mike Pence spoke out against Hillary Clinton saying half of Trump supporters could be put in “the basket of deplorables.” “They are not a basket of anything,” Pence said on Sept. 10. “They are Americans and they deserve your respect.” (FRC Action)   “Now, some of those folks — they are irredeemable, but thankfully they are not America.” Condemnation came swiftly from Trump’s allies and from the candidate himself, who on Twitter called the remarks “so insulting” and predicted that Clinton would pay a price in the polls.  In a statement issued later Saturday, Trump said that Clinton’s “true feelings” had come out. “How can she be President of our country when she has such contempt and disdain for so many great Americans?” Trump said. “Hillary Clinton should be ashamed of herself.” Trump’s campaign manager, Kellyanne Conway, called for Clinton to apologize, something that Trump himself has never done in the face of controversy. Indiana Gov. Mike Pence, Trump’s running mate, also weighed in, comparing Clinton’s remarks to President Obama’s controversial 2008 comments about people who “cling to guns or religion.” Pence said that such statements should preclude her from being elected president. Others compared the remark to 2012 Republican nominee Mitt Romney’s infamous “47 percent” comment. Even if the comparison was imprecise — at most, Clinton’s comments referred to about one-quarter of the electorate — the Trump campaign has already sought to use the comparison to further define Clinton in the remaining months of the campaign. Pointing out the similarities, Trump retweeted a September 2012 post from the Obama campaign’s Twitter account in response to Romney’s comment: “RT if you agree: We need a President who is fighting for all Americans, not one who writes off nearly half the country.”         1 of 40       Full Screen Autoplay  Close                                                                                                       Skip Ad   ×           Hillary Clinton on the campaign trail      View Photos   The Democratic presidential nominee hits the road after her party’s national convention.    Caption   The Democratic presidential nominee hits the road after her party’s national convention.  Sept. 9, 2016 Democratic presidential nominee Hillary Clinton speaks at the LGBT for Hillary Gala at the Cipriani Club in New York. Andrew Harnik/AP  Buy Photo          Wait 1 second to continue.   .wp-volt-gal-preroll-video{width:100%;height:100%}        In 2012, Trump defended Romney’s “47 percent” comments, counseling the then-Republican nominee not to apologize for them.  [Did Hillary Clinton just make her own ‘47 percent’ gaffe?]  In his remarks, recorded at a private fundraiser, Romney asserted that 47 percent of voters “will vote for the president no matter what” because they are “dependent upon government,” “believe that they are victims” and “pay no income tax.” The Republican was widely criticized for giving the impression that he was writing off half the country because of their economic status. Clinton issued a statement Saturday afternoon saying that she regretted using the word “half” to describe the Trump supporters she was referring to. “That was wrong,” Clinton said. “But let’s be clear, what’s really ‘deplorable’ is that Donald Trump hired a major advocate for the so-called ‘alt-right’ movement to run his campaign and that David Duke and other white supremacists see him as a champion of their values.” In the statement, Clinton blasted Trump specifically for his feud with the family of a Muslim American Army officer who died in Iraq, his attacks against a Hispanic federal judge hearing two cases against him and his prominent role in the “birther” movement promoting the idea that Obama was not born in the United States. In her remarks at the fundraiser, Clinton also called for empathy for the other “half” of Trump’s supporters. “That other basket of people are people who feel that the government has let them down, the economy has let them down, nobody cares about them, nobody worries about what happens to their lives and their futures, and they’re just desperate for change,” Clinton said on Friday night. “It doesn’t really even matter where it comes from. “Those are people we have to understand and empathize with as well,” she added.        [Democrats wonder and worry: Why isn’t Clinton far ahead of Trump?]  Clinton’s running mate, Sen. Tim Kaine (Va.), said Saturday in an interview with The Washington Post that Clinton had nothing to apologize for. “She was generalizing and saying there are some of his supporters we’ll never get because they’re motivated by some dark motives, but there are other supporters that have legitimate concerns and questions about the economy, and we’ve got to speak to them in the campaign,” he said. “And even to the extent that they vote against us, we still have to respond to their concerns if we have the opportunity to govern.” In an election cycle that has been more characterized by Trump’s controversies, Clinton’s comments represent a reversal of fortune and a rare moment when she stepped on a news cycle that had not been favorable to Trump. The flap also comes as polls show Trump narrowing Clinton’s lead nationally and in battleground states. Ever since he installed new campaign leadership about three weeks ago, Trump has softened his tone on the campaign trail and mostly stuck to prepared rally speeches loaded onto teleprompters. That level of discipline seemed to fade Friday night during a rally in a packed arena in the Florida Panhandle. Trump said that as president, he would shoot Iranian boats out of the water if they make improper “gestures” toward American vessels, that Clinton is so protected from having to face consequences that she could murder someone in front of 20,000 witnesses and not face prosecution, and that voters need to be “very, very vigilant” on Election Day. Hours before Clinton’s remarks at the fundraiser, Trump was facing new criticism for appearing on a state-owned Russian television network to praise Russian President Vladi­mir Putin and disparage U.S. foreign policy. Clinton had seized on those comments at a news conference earlier in the day. “I’m not sure anything surprises us anymore,” Clinton said. “But I was certainly disappointed that someone running for president of the United States would continue this unseemly identification with and praise of the Russian president, including on Russian television.”  [Trump: Iranian boats that make improper ‘gestures’ will be ‘shot out of the water’]  After news broke of Clinton’s “deplorables” comment, Trump’s allies seized on the moment to paint Clinton as dismissive of a large portion of voters. It wasn’t the first time Clinton had used that language. In an interview this past week with Israeli TV, she said something similar — but without quantifying the amount of Trump’s support that qualified for the label “deplorable.” Clinton also delivered a major speech weeks ago devoted to Trump’s association with the alt-right, the name used by a movement of white nationalist ideology. She accused Trump of irresponsibly highlighting that movement by amplifying its messages on Twitter. The speech was aimed at moderate Republicans and independent voters, whom the campaign is encouraging to break from Trump in part because of the alt-right figures who support him. Clinton reprised that part of her case against Trump at the fundraising event Friday night. But the furor over “deplorables” put her aides and supporters on the defensive, and they attempted to refocus attention on the parts of Clinton’s remarks that called for mutual understanding. Others pointed out recent polling showing that 7 percent of Trump’s own supporters think he is racist. According to a PRRI poll conducted over the summer, 77 percent of Trump supporters say they are bothered when they come in contact with immigrants who speak little or no English, compared with half of Americans overall. And 83 percent of Trump supporters say that Islam is contradictory to American values, compared with 57 percent of Americans overall. Some Clinton allies acknowledged the perils of painting voters with too broad a brush, but they insisted that Clinton was right to denounce hatred. “I think it’s a bad idea for any candidate to make generalizations about voters like an amateur pollster or sociologist would,” former Obama speechwriter Jon Favreau wrote on Twitter. “But Trump does it every single day, and it’s always worse. “Why weren’t there comparisons to 47% when Trump said that all black lives were a ‘disaster?’ Or when he said that all Muslims are helping terrorists hide among us?” he tweeted. Trump’s aides — who see their candidate as an “outsider” fighting against Washington elites — see an opportunity to suggest not only that Clinton doesn’t understand struggling Americans, but that she also has disdain for them. The Republican National Committee held a conference call Saturday afternoon with campaign aides and surrogates, tearing into Clinton’s remarks and saying that Trump, in contrast, would be “a president for all people.”  “Mr. Trump is running to be president for all Americans; black, white, Latino, men, women, everybody,” Trump spokesman Jason Miller said on the call, which also included Rep. Marsha Blackburn and Pastor Darrell Scott        Jenna Johnson and John Wagner in Richmond contributed to this report. \n",
      "Bootstrap sample 1 out of 1\n",
      "Article 1 out of 1\n",
      "LDA topic number 1 out of 2\n",
      "N topics: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Hillary Clinton’s claim at a fundraiser that half of Donald Trump’s supporters fit into a “basket of deplorables” prompted a swift and negative reaction Saturday from Republicans, including denunciations and calls for her to apologize.', 'The comments echoed an accusation that Clinton had levied previously — that Trump appeals to and amplifies racist, xenophobic and anti-Semitic viewpoints.', 'But Clinton triggered a fresh controversy by claiming that “half” of Trump’s supporters fit that description.', 'At a key moment in the campaign, when both candidates are trying to sharpen their focus for the final, post-Labor Day sprint, Clinton’s remarks took attention from Trump’s spate of gaffes last week and also from her own effort to turn the public’s attention to her qualifications for office and vision for the nation.', '“You know, to just be grossly generalistic, you could put half of Trump’s supporters into what I call the ‘basket of deplorables.’ Right?” Clinton said to applause and laughter from supporters at the LGBT for Hillary fundraiser Friday night in New York that also featured a performance by Barbra Streisand.', '“The racist, sexist, homophobic, xenophobic, Islamophobic — you name it.” She continued: “He has given voice to their websites that used to only have 11,000 people — now have 11 million.', 'He tweets and retweets their offensive, hateful, mean-spirited rhetoric.', 'Republican vice presidential nominee Mike Pence spoke out against Hillary Clinton saying half of Trump supporters could be put in “the basket of deplorables.” “They are not a basket of anything,” Pence said on Sept. 10.', '“They are Americans and they deserve your respect.” (FRC Action)   “Now, some of those folks — they are irredeemable, but thankfully they are not America.” Condemnation came swiftly from Trump’s allies and from the candidate himself, who on Twitter called the remarks “so insulting” and predicted that Clinton would pay a price in the polls.', 'In a statement issued later Saturday, Trump said that Clinton’s “true feelings” had come out.', '“How can she be President of our country when she has such contempt and disdain for so many great Americans?” Trump said.', '“Hillary Clinton should be ashamed of herself.” Trump’s campaign manager, Kellyanne Conway, called for Clinton to apologize, something that Trump himself has never done in the face of controversy.', 'Indiana Gov.', 'Mike Pence, Trump’s running mate, also weighed in, comparing Clinton’s remarks to President Obama’s controversial 2008 comments about people who “cling to guns or religion.” Pence said that such statements should preclude her from being elected president.', 'Others compared the remark to 2012 Republican nominee Mitt Romney’s infamous “47\\xa0percent” comment.', 'Even if the comparison was imprecise — at most, Clinton’s comments referred to about one-quarter of the electorate — the Trump campaign has already sought to use the comparison to further define Clinton in the remaining months of the campaign.', 'Pointing out the similarities, Trump retweeted a September 2012 post from the Obama campaign’s Twitter account in response to Romney’s comment: “RT if you agree: We need a President who is fighting for all Americans, not one who writes off nearly half the country.”         1 of 40       Full Screen Autoplay  Close                                                                                                       Skip Ad   ×           Hillary Clinton on the campaign trail      View Photos   The Democratic presidential nominee hits the road after her party’s national convention.', 'Caption   The Democratic presidential nominee hits the road after her party’s national convention.', 'Sept. 9, 2016 Democratic presidential nominee Hillary Clinton speaks at the LGBT for Hillary Gala at the Cipriani Club in New York.', 'Andrew Harnik/AP  Buy Photo          Wait 1 second to continue.', '.wp-volt-gal-preroll-video{width:100%;height:100%}        In 2012, Trump defended Romney’s “47 percent” comments, counseling the then-Republican nominee not to apologize for them.', '[Did Hillary Clinton just make her own ‘47 percent’ gaffe?]', 'In his remarks, recorded at a private fundraiser, Romney asserted that 47\\xa0percent of voters “will vote for the president no matter what” because they are “dependent upon government,” “believe that they are victims” and “pay no income tax.” The Republican was widely criticized for giving the impression that he was writing off half the country because of their economic status.', 'Clinton issued a statement Saturday afternoon saying that she regretted using the word “half” to describe the Trump supporters she was referring to.', '“That was wrong,” Clinton said.', '“But let’s be clear, what’s really ‘deplorable’ is that Donald Trump hired a major advocate for the so-called ‘alt-right’ movement to run his campaign and that David Duke and other white supremacists see him as a champion of their values.” In the statement, Clinton blasted Trump specifically for his feud with the family of a Muslim American Army officer who died in Iraq, his attacks against a Hispanic federal judge hearing two cases against him and his prominent role in the “birther” movement promoting the idea that Obama was not born in the United States.', 'In her remarks at the fundraiser, Clinton also called for empathy for the other “half” of Trump’s supporters.', '“That other basket of people are people who feel that the government has let them down, the economy has let them down, nobody cares about them, nobody worries about what happens to their lives and their futures, and they’re just desperate for change,” Clinton said on Friday night.', '“It doesn’t really even matter where it comes from.', '“Those are people we have to understand and empathize with as well,” she added.', '[Democrats wonder and worry: Why isn’t Clinton far ahead of Trump?]', 'Clinton’s running mate, Sen. Tim Kaine (Va.), said Saturday in an interview with The Washington Post that Clinton had nothing to apologize for.', '“She was generalizing and saying there are some of his supporters we’ll never get because they’re motivated by some dark motives, but there are other supporters that have legitimate concerns and questions about the economy, and we’ve got to speak to them in the campaign,” he said.', '“And even to the extent that they vote against us, we still have to respond to their concerns if we have the opportunity to govern.” In an election cycle that has been more characterized by Trump’s controversies, Clinton’s comments represent a reversal of fortune and a rare moment when she stepped on a news cycle that had not been favorable to Trump.', 'The flap also comes as polls show Trump narrowing Clinton’s lead nationally and in battleground states.', 'Ever since he installed new campaign leadership about three weeks ago, Trump has softened his tone on the campaign trail and mostly stuck to prepared rally speeches loaded onto teleprompters.', 'That level of discipline seemed to fade Friday night during a rally in a packed arena in the Florida Panhandle.', 'Trump said that as president, he would shoot Iranian boats out of the water if they make improper “gestures” toward American vessels, that Clinton is so protected from having to face consequences that she could murder someone in front of 20,000 witnesses and not face prosecution, and that voters need to be “very, very vigilant” on Election Day.', 'Hours before Clinton’s remarks at the fundraiser, Trump was facing new criticism for appearing on a state-owned Russian television network to praise Russian President Vladi\\xadmir Putin and disparage U.S. foreign policy.', 'Clinton had seized on those comments at a news conference earlier in the day.', '“I’m not sure anything surprises us anymore,” Clinton said.', '“But I was certainly disappointed that someone running for president of the United States would continue this unseemly identification with and praise of the Russian president, including on Russian television.”  [Trump: Iranian boats that make improper ‘gestures’ will be ‘shot out of the water’]  After news broke of Clinton’s “deplorables” comment, Trump’s allies seized on the moment to paint Clinton as dismissive of a large portion of voters.', 'It wasn’t the first time Clinton had used that language.', 'In an interview this past week with Israeli TV, she said something similar — but without quantifying the amount of Trump’s support that qualified for the label “deplorable.” Clinton also delivered a major speech weeks ago devoted to Trump’s association with the alt-right, the name used by a movement of white nationalist ideology.', 'She accused Trump of irresponsibly highlighting that movement by amplifying its messages on Twitter.', 'The speech was aimed at moderate Republicans and independent voters, whom the campaign is encouraging to break from Trump in part because of the alt-right figures who support him.', 'Clinton reprised that part of her case against Trump at the fundraising event Friday night.', 'But the furor over “deplorables” put her aides and supporters on the defensive, and they attempted to refocus attention on the parts of Clinton’s remarks that called for mutual understanding.', 'Others pointed out recent polling showing that 7\\xa0percent of Trump’s own supporters think he is racist.', 'According to a PRRI poll conducted over the summer, 77\\xa0percent of Trump supporters say they are bothered when they come in contact with immigrants who speak little or no English, compared with half of Americans overall.', 'And 83\\xa0percent of Trump supporters say that Islam is contradictory to American values, compared with 57\\xa0percent of Americans overall.', 'Some Clinton allies acknowledged the perils of painting voters with too broad a brush, but they insisted that Clinton was right to denounce hatred.', '“I think it’s a bad idea for any candidate to make generalizations about voters like an amateur pollster or sociologist would,” former Obama speechwriter Jon Favreau wrote on Twitter.', '“But Trump does it every single day, and it’s always worse.', '“Why weren’t there comparisons to 47% when Trump said that all black lives were a ‘disaster?’ Or when he said that all Muslims are helping terrorists hide among us?” he tweeted.', 'Trump’s aides — who see their candidate as an “outsider” fighting against Washington elites — see an opportunity to suggest not only that Clinton doesn’t understand struggling Americans, but that she also has disdain for them.', 'The Republican National Committee held a conference call Saturday afternoon with campaign aides and surrogates, tearing into Clinton’s remarks and saying that Trump, in contrast, would be “a president for all people.”  “Mr.', 'Trump is running to be president for all Americans; black, white, Latino, men, women, everybody,” Trump spokesman Jason Miller said on the call, which also included Rep. Marsha Blackburn and Pastor Darrell Scott        Jenna Johnson and John Wagner in Richmond contributed to this report.']\n",
      "Bootstrap sample 1 out of 1\n",
      "Article 1 out of 1\n",
      "LDA topic number 2 out of 2\n",
      "N topics: 3\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "decoding to str: need a bytes-like object, list found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-277-2f3910f4fb2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;31m# for counting word frequencies\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0marticle_processed_whole\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_all_articles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marticle_text\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0marticle_processed_whole\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_stopwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle_processed_whole\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mstop_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/post PhD positions search/insightDataScience/project/debiaser/text_processing_functions.py\u001b[0m in \u001b[0;36mprocess_all_articles\u001b[0;34m(documents, nlp)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;31m# process documents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mdocument_processed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;31m# append to list of processed documents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/post PhD positions search/insightDataScience/project/debiaser/text_processing_functions.py\u001b[0m in \u001b[0;36mprocess_text\u001b[0;34m(article_text, nlp)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;31m# run gensim preprocess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0marticle_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimple_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeacc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marticle_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/debiaser/lib/python3.7/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36msimple_preprocess\u001b[0;34m(doc, deacc, min_len, max_len)\u001b[0m\n\u001b[1;32m    312\u001b[0m     \"\"\"\n\u001b[1;32m    313\u001b[0m     tokens = [\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0mtoken\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeacc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeacc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmin_len\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mmax_len\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m     ]\n",
      "\u001b[0;32m~/anaconda3/envs/debiaser/lib/python3.7/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(text, lowercase, deacc, encoding, errors, to_lower, lower)\u001b[0m\n\u001b[1;32m    263\u001b[0m     \"\"\"\n\u001b[1;32m    264\u001b[0m     \u001b[0mlowercase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlowercase\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mto_lower\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlower\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 265\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_unicode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    266\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlowercase\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/debiaser/lib/python3.7/site-packages/gensim/utils.py\u001b[0m in \u001b[0;36many2unicode\u001b[0;34m(text, encoding, errors)\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 368\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: decoding to str: need a bytes-like object, list found"
     ]
    }
   ],
   "source": [
    "# choose the number of LDA topics\n",
    "# num_lda_topics = [1,2,3,4,5,6,7,8,9,10]\n",
    "num_lda_topics = [1,2]\n",
    "\n",
    "# do by sentences\n",
    "do_sentences = 1\n",
    "\n",
    "# to show plots per  run\n",
    "do_plot = 0\n",
    "\n",
    "# to print output\n",
    "do_print = 1\n",
    "\n",
    "# to print progress of testing\n",
    "do_progress_print = 1\n",
    "\n",
    "# number of passes LDA does through corpus (hyperparameter)\n",
    "n_passes = 6\n",
    "\n",
    "unique_topic_words = 1\n",
    "\n",
    "# number of words to use in search\n",
    "# (or number of top most often frequencies of words, e.g., use 5 highest word frequencies)\n",
    "# (This could be more than 5 words if some words show up equally as often and among the msot often of all words)\n",
    "n_topic_words = 5\n",
    "\n",
    "# dummy nlp variable, for now not in use because lemmatization not in use\n",
    "nlp = []\n",
    "\n",
    "# empty matrix for perplexity scores\n",
    "perplexity_scores = np.zeros(( n_bootstrap_samples, n_articles_per_sample, len(num_lda_topics) ))\n",
    "\n",
    "# empty matrix for coherence scores\n",
    "coherence_scores = np.zeros(( n_bootstrap_samples, n_articles_per_sample, len(num_lda_topics) ))\n",
    "\n",
    "# empty matrix for probability vs word in topic (doing for n = 1 topic only)\n",
    "n_topic_words_single_topic_analysis = 10\n",
    "topic_word_probs = np.zeros(( n_bootstrap_samples, n_articles_per_sample, n_topic_words_single_topic_analysis ))\n",
    "\n",
    "# empty matrix for jaccard sim, set to nan in case any have 0 similarity\n",
    "jaccard_sim_all = np.zeros(( n_bootstrap_samples, n_articles_per_sample, n_topic_words_single_topic_analysis ))\n",
    "jaccard_sim_all[:] = np.nan\n",
    "\n",
    "# empty matrix for cosine sim, set to nan in case any have 0 similarity\n",
    "cosine_sim_all = np.zeros(( n_bootstrap_samples, n_articles_per_sample, n_topic_words_single_topic_analysis ))\n",
    "cosine_sim_all[:] = np.nan\n",
    "\n",
    "# empty matrix for length of most common words vec\n",
    "number_most_common_words = np.zeros(( n_bootstrap_samples, n_articles_per_sample, n_topic_words_single_topic_analysis ))\n",
    "\n",
    "# counter for bootstrap sampling\n",
    "counter_nboot = -1\n",
    "\n",
    "for i in range(n_samples):\n",
    "    \n",
    "    # draw random articles\n",
    "#     articles_df_random_subset = all_news_df.sample(n=n_articles_per_sample)\n",
    "    \n",
    "    counter_nboot += 1\n",
    "\n",
    "    # counter for articles\n",
    "    counter_article = -1\n",
    "    \n",
    "    for article_text in articles_df_random_subset['content']:\n",
    "        \n",
    "        counter_article += 1\n",
    "        \n",
    "        for ind_num_topics, num_topic in enumerate(num_lda_topics):\n",
    "\n",
    "            if do_print:\n",
    "                print(article_text)\n",
    "                \n",
    "            if do_progress_print:\n",
    "                print(f'Bootstrap sample {counter_nboot+1} out of {n_samples}')\n",
    "                print(f'Article {counter_article+1} out of {n_articles_per_sample}')\n",
    "                print(f'LDA topic number {ind_num_topics+1} out of {len(num_lda_topics)}')\n",
    "                print(f'N topics: {num_topic+1}')\n",
    "                    \n",
    "\n",
    "            # for counting word frequencies\n",
    "            article_processed_whole = process_all_articles([article_text],nlp)\n",
    "\n",
    "            article_processed_whole = remove_stopwords(article_processed_whole,stop_words)\n",
    "\n",
    "\n",
    "            if do_sentences:\n",
    "\n",
    "                # break article into sentences\n",
    "                article_text = tokenize.sent_tokenize(article_text)\n",
    "\n",
    "                # process article\n",
    "                article_processed = process_all_articles(article_text,nlp)\n",
    "\n",
    "                # remove stopwords\n",
    "                article_processed = remove_stopwords(article_processed,stop_words)\n",
    "\n",
    "            else:\n",
    "\n",
    "                # process article\n",
    "                article_processed = process_all_articles([article_text],nlp)\n",
    "\n",
    "                # remove stopwords\n",
    "                article_processed = remove_stopwords(article_processed,stop_words)\n",
    "\n",
    "\n",
    "            # get corpus, dictionary, bag of words\n",
    "            processed_corpus, processed_dictionary, bow_corpus = get_simple_corpus_dictionary_bow(article_processed)\n",
    "\n",
    "            # generate the LDA model\n",
    "            lda = LdaModel(corpus = bow_corpus,\n",
    "                             num_topics = num_topic,\n",
    "                             id2word = processed_dictionary,\n",
    "                             passes = n_passes)\n",
    "            \n",
    "            # calculate and store perplexity\n",
    "            perplexity = lda.log_perplexity(bow_corpus)\n",
    "            perplexity_scores[counter_nboot,counter_article,ind_num_topics] = perplexity\n",
    "\n",
    "            # calculate and store coherence\n",
    "            coherence_model_lda = CoherenceModel(model=lda, texts=article_processed, dictionary=processed_dictionary, coherence='c_v')\n",
    "            coherence_lda = coherence_model_lda.get_coherence()\n",
    "            coherence_scores[counter_nboot,counter_article,ind_num_topics] = coherence_lda\n",
    "            \n",
    "            # get the topics from the lda model\n",
    "            lda_topics = lda.show_topics(formatted=False)\n",
    "\n",
    "            # get the top topic words\n",
    "            lda_top_topic_words_string, lda_top_topic_words_list = get_lda_top_topic_words(lda_topics,num_topic,unique_topic_words,n_topic_words)\n",
    "            \n",
    "            # for case of only one topic, store matrix of word probs\n",
    "            if num_topic == 1:\n",
    "\n",
    "                lda_topic_word_probs = get_single_topic_word_probs(lda_topics,n_topic_words_single_topic_analysis)\n",
    "                        \n",
    "                # add to matrix of word probs\n",
    "                topic_word_probs[counter_nboot,counter_article,:] = lda_topic_word_probs[:,0]\n",
    "\n",
    "            # count word frequencies\n",
    "            word_dict_count, word_counts_top, most_common_words_list, most_common_words_string = count_word_frequencies(article_processed_whole,n_topic_words)\n",
    "\n",
    "            # get jaccard similarity\n",
    "            jaccard_sim = get_jaccard_sim(lda_top_topic_words_list, most_common_words_list)\n",
    "            jaccard_sim_all[counter_nboot,counter_article,ind_num_topics] = jaccard_sim\n",
    "            \n",
    "            # get word vectors for common words and lda top words\n",
    "            vec_most_common_words = processed_dictionary.doc2bow(most_common_words_list,return_missing=False)\n",
    "            vec_lda_top_topic_words = processed_dictionary.doc2bow(lda_top_topic_words_list,return_missing=False)\n",
    "            \n",
    "            # calculate cosine similarity\n",
    "            cosine_sim = calculate_cosine_similarity(vec_most_common_words,vec_lda_top_topic_words)\n",
    "            cosine_sim_all[counter_nboot,counter_article,ind_num_topics] = cosine_sim\n",
    "            \n",
    "            # add number of words from counting top most frequent\n",
    "            number_most_common_words[counter_nboot,counter_article,ind_num_topics] = len(most_common_words_list)\n",
    "            \n",
    "            if do_plot:\n",
    "                plt.figure(figsize=(15,5));\n",
    "                plt.bar(topics_means,means_sorted,yerr=std_sorted);\n",
    "                plt.ylabel('Mean probability');\n",
    "                sns.set_context('talk', font_scale=1.5);\n",
    "                plt.xticks(rotation=90);\n",
    "                plt.show();\n",
    "                plt.clf();\n",
    "    #             plt.savefig('./eda_figs/mean_prob_vs_topic_big_ten_resumes.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "                plt.figure(figsize=(15,5));\n",
    "                plt.bar(topics_freq,freq_sorted);\n",
    "                plt.ylabel('N');\n",
    "                # plt.xlabel('Topics')\n",
    "                sns.set_context('talk', font_scale=1.5);\n",
    "                plt.xticks(rotation=90);\n",
    "                plt.show();\n",
    "                plt.clf();\n",
    "    #             plt.savefig('./edafigs/frequency_vs_topic_big_ten_resumes.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting for perplexity and coherence scores\n",
    "\n",
    "# get means across samples per bootstrap sample\n",
    "coherence_scores_mean = np.mean(coherence_scores,axis=1)\n",
    "perplexity_scores_mean = np.mean(perplexity_scores,axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting for probability vs words, when single topics used\n",
    "topic_word_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing word counting with lda\n",
    "jaccard_sim_all\n",
    "\n",
    "cosine_sim_all\n",
    "\n",
    "number_most_common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04653657],\n",
       "       [0.01589036],\n",
       "       [0.01021559],\n",
       "       [0.01021537],\n",
       "       [0.00908045],\n",
       "       [0.00794533],\n",
       "       [0.00794528],\n",
       "       [0.00681033],\n",
       "       [0.00681031],\n",
       "       [0.00681031]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# empty matrix for perplexity scores\n",
    "perplexity_scores = np.zeros(( n_bootstrap_samples, n_articles_per_sample, len(num_lda_topics) ))\n",
    "\n",
    "# empty matrix for coherence scores\n",
    "coherence_scores = np.zeros(( n_bootstrap_samples, n_articles_per_sample, len(num_lda_topics) ))\n",
    "\n",
    "# empty matrix for probability vs word in topic (doing for n = 1 topic only)\n",
    "n_topic_words_single_topic_analysis = 10\n",
    "topic_word_probs = np.zeros(( n_bootstrap_samples, n_articles_per_sample, n_topic_words_single_topic_analysis ))\n",
    "\n",
    "# empty matrix for jaccard sim, set to nan in case any have 0 similarity\n",
    "jaccard_sim_all = np.zeros(( n_bootstrap_samples, n_articles_per_sample, n_topic_words_single_topic_analysis ))\n",
    "jaccard_sim_all[:] = np.nan\n",
    "\n",
    "# empty matrix for cosine sim, set to nan in case any have 0 similarity\n",
    "cosine_sim_all = np.zeros(( n_bootstrap_samples, n_articles_per_sample, n_topic_words_single_topic_analysis ))\n",
    "cosine_sim_all[:] = np.nan\n",
    "\n",
    "# empty matrix for length of most common words vec\n",
    "number_most_common_words = np.zeros(( n_bootstrap_samples, n_articles_per_sample, n_topic_words_single_topic_analysis ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' Hillary Clinton’s claim at a fundraiser that half of Donald Trump’s supporters fit into a “basket of deplorables” prompted a swift and negative reaction Saturday from Republicans, including denunciations and calls for her to apologize.', 'The comments echoed an accusation that Clinton had levied previously — that Trump appeals to and amplifies racist, xenophobic and anti-Semitic viewpoints.', 'But Clinton triggered a fresh controversy by claiming that “half” of Trump’s supporters fit that description.', 'At a key moment in the campaign, when both candidates are trying to sharpen their focus for the final, post-Labor Day sprint, Clinton’s remarks took attention from Trump’s spate of gaffes last week and also from her own effort to turn the public’s attention to her qualifications for office and vision for the nation.', '“You know, to just be grossly generalistic, you could put half of Trump’s supporters into what I call the ‘basket of deplorables.’ Right?” Clinton said to applause and laughter from supporters at the LGBT for Hillary fundraiser Friday night in New York that also featured a performance by Barbra Streisand.', '“The racist, sexist, homophobic, xenophobic, Islamophobic — you name it.” She continued: “He has given voice to their websites that used to only have 11,000 people — now have 11 million.', 'He tweets and retweets their offensive, hateful, mean-spirited rhetoric.', 'Republican vice presidential nominee Mike Pence spoke out against Hillary Clinton saying half of Trump supporters could be put in “the basket of deplorables.” “They are not a basket of anything,” Pence said on Sept. 10.', '“They are Americans and they deserve your respect.” (FRC Action)   “Now, some of those folks — they are irredeemable, but thankfully they are not America.” Condemnation came swiftly from Trump’s allies and from the candidate himself, who on Twitter called the remarks “so insulting” and predicted that Clinton would pay a price in the polls.', 'In a statement issued later Saturday, Trump said that Clinton’s “true feelings” had come out.', '“How can she be President of our country when she has such contempt and disdain for so many great Americans?” Trump said.', '“Hillary Clinton should be ashamed of herself.” Trump’s campaign manager, Kellyanne Conway, called for Clinton to apologize, something that Trump himself has never done in the face of controversy.', 'Indiana Gov.', 'Mike Pence, Trump’s running mate, also weighed in, comparing Clinton’s remarks to President Obama’s controversial 2008 comments about people who “cling to guns or religion.” Pence said that such statements should preclude her from being elected president.', 'Others compared the remark to 2012 Republican nominee Mitt Romney’s infamous “47\\xa0percent” comment.', 'Even if the comparison was imprecise — at most, Clinton’s comments referred to about one-quarter of the electorate — the Trump campaign has already sought to use the comparison to further define Clinton in the remaining months of the campaign.', 'Pointing out the similarities, Trump retweeted a September 2012 post from the Obama campaign’s Twitter account in response to Romney’s comment: “RT if you agree: We need a President who is fighting for all Americans, not one who writes off nearly half the country.”         1 of 40       Full Screen Autoplay  Close                                                                                                       Skip Ad   ×           Hillary Clinton on the campaign trail      View Photos   The Democratic presidential nominee hits the road after her party’s national convention.', 'Caption   The Democratic presidential nominee hits the road after her party’s national convention.', 'Sept. 9, 2016 Democratic presidential nominee Hillary Clinton speaks at the LGBT for Hillary Gala at the Cipriani Club in New York.', 'Andrew Harnik/AP  Buy Photo          Wait 1 second to continue.', '.wp-volt-gal-preroll-video{width:100%;height:100%}        In 2012, Trump defended Romney’s “47 percent” comments, counseling the then-Republican nominee not to apologize for them.', '[Did Hillary Clinton just make her own ‘47 percent’ gaffe?]', 'In his remarks, recorded at a private fundraiser, Romney asserted that 47\\xa0percent of voters “will vote for the president no matter what” because they are “dependent upon government,” “believe that they are victims” and “pay no income tax.” The Republican was widely criticized for giving the impression that he was writing off half the country because of their economic status.', 'Clinton issued a statement Saturday afternoon saying that she regretted using the word “half” to describe the Trump supporters she was referring to.', '“That was wrong,” Clinton said.', '“But let’s be clear, what’s really ‘deplorable’ is that Donald Trump hired a major advocate for the so-called ‘alt-right’ movement to run his campaign and that David Duke and other white supremacists see him as a champion of their values.” In the statement, Clinton blasted Trump specifically for his feud with the family of a Muslim American Army officer who died in Iraq, his attacks against a Hispanic federal judge hearing two cases against him and his prominent role in the “birther” movement promoting the idea that Obama was not born in the United States.', 'In her remarks at the fundraiser, Clinton also called for empathy for the other “half” of Trump’s supporters.', '“That other basket of people are people who feel that the government has let them down, the economy has let them down, nobody cares about them, nobody worries about what happens to their lives and their futures, and they’re just desperate for change,” Clinton said on Friday night.', '“It doesn’t really even matter where it comes from.', '“Those are people we have to understand and empathize with as well,” she added.', '[Democrats wonder and worry: Why isn’t Clinton far ahead of Trump?]', 'Clinton’s running mate, Sen. Tim Kaine (Va.), said Saturday in an interview with The Washington Post that Clinton had nothing to apologize for.', '“She was generalizing and saying there are some of his supporters we’ll never get because they’re motivated by some dark motives, but there are other supporters that have legitimate concerns and questions about the economy, and we’ve got to speak to them in the campaign,” he said.', '“And even to the extent that they vote against us, we still have to respond to their concerns if we have the opportunity to govern.” In an election cycle that has been more characterized by Trump’s controversies, Clinton’s comments represent a reversal of fortune and a rare moment when she stepped on a news cycle that had not been favorable to Trump.', 'The flap also comes as polls show Trump narrowing Clinton’s lead nationally and in battleground states.', 'Ever since he installed new campaign leadership about three weeks ago, Trump has softened his tone on the campaign trail and mostly stuck to prepared rally speeches loaded onto teleprompters.', 'That level of discipline seemed to fade Friday night during a rally in a packed arena in the Florida Panhandle.', 'Trump said that as president, he would shoot Iranian boats out of the water if they make improper “gestures” toward American vessels, that Clinton is so protected from having to face consequences that she could murder someone in front of 20,000 witnesses and not face prosecution, and that voters need to be “very, very vigilant” on Election Day.', 'Hours before Clinton’s remarks at the fundraiser, Trump was facing new criticism for appearing on a state-owned Russian television network to praise Russian President Vladi\\xadmir Putin and disparage U.S. foreign policy.', 'Clinton had seized on those comments at a news conference earlier in the day.', '“I’m not sure anything surprises us anymore,” Clinton said.', '“But I was certainly disappointed that someone running for president of the United States would continue this unseemly identification with and praise of the Russian president, including on Russian television.”  [Trump: Iranian boats that make improper ‘gestures’ will be ‘shot out of the water’]  After news broke of Clinton’s “deplorables” comment, Trump’s allies seized on the moment to paint Clinton as dismissive of a large portion of voters.', 'It wasn’t the first time Clinton had used that language.', 'In an interview this past week with Israeli TV, she said something similar — but without quantifying the amount of Trump’s support that qualified for the label “deplorable.” Clinton also delivered a major speech weeks ago devoted to Trump’s association with the alt-right, the name used by a movement of white nationalist ideology.', 'She accused Trump of irresponsibly highlighting that movement by amplifying its messages on Twitter.', 'The speech was aimed at moderate Republicans and independent voters, whom the campaign is encouraging to break from Trump in part because of the alt-right figures who support him.', 'Clinton reprised that part of her case against Trump at the fundraising event Friday night.', 'But the furor over “deplorables” put her aides and supporters on the defensive, and they attempted to refocus attention on the parts of Clinton’s remarks that called for mutual understanding.', 'Others pointed out recent polling showing that 7\\xa0percent of Trump’s own supporters think he is racist.', 'According to a PRRI poll conducted over the summer, 77\\xa0percent of Trump supporters say they are bothered when they come in contact with immigrants who speak little or no English, compared with half of Americans overall.', 'And 83\\xa0percent of Trump supporters say that Islam is contradictory to American values, compared with 57\\xa0percent of Americans overall.', 'Some Clinton allies acknowledged the perils of painting voters with too broad a brush, but they insisted that Clinton was right to denounce hatred.', '“I think it’s a bad idea for any candidate to make generalizations about voters like an amateur pollster or sociologist would,” former Obama speechwriter Jon Favreau wrote on Twitter.', '“But Trump does it every single day, and it’s always worse.', '“Why weren’t there comparisons to 47% when Trump said that all black lives were a ‘disaster?’ Or when he said that all Muslims are helping terrorists hide among us?” he tweeted.', 'Trump’s aides — who see their candidate as an “outsider” fighting against Washington elites — see an opportunity to suggest not only that Clinton doesn’t understand struggling Americans, but that she also has disdain for them.', 'The Republican National Committee held a conference call Saturday afternoon with campaign aides and surrogates, tearing into Clinton’s remarks and saying that Trump, in contrast, would be “a president for all people.”  “Mr.', 'Trump is running to be president for all Americans; black, white, Latino, men, women, everybody,” Trump spokesman Jason Miller said on the call, which also included Rep. Marsha Blackburn and Pastor Darrell Scott        Jenna Johnson and John Wagner in Richmond contributed to this report.']\n",
      "most common words:  hillary clinton supporters remarks nominee americans voters\n",
      "word counts for most most common words: [40, 13, 8, 7, 6]\n",
      "lda top topic words:  clinton supporters hillary remarks americans\n"
     ]
    }
   ],
   "source": [
    "\n",
    "        \n",
    "print(article_text)\n",
    "print('most common words:',most_common_words_string)\n",
    "print('word counts for most most common words:',word_counts_top)\n",
    "print('lda top topic words:',lda_top_topic_words)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " hillary clinton supporters remarks nominee americans voters\n",
      " clinton supporters hillary remarks americans\n"
     ]
    }
   ],
   "source": [
    "print(most_common_words_string)\n",
    "print(lda_top_topic_words_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7142857142857143"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_jaccard_sim(lda_top_topic_words_list, most_common_words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_most_common_words = processed_dictionary.doc2bow(most_common_words_list,return_missing=False)\n",
    "\n",
    "vec_lda_top_topic_words = processed_dictionary.doc2bow(lda_top_topic_words_list,return_missing=False)\n",
    "# vec_lda_top_topic_words.append((59,0))\n",
    "# vec_lda_top_topic_words.append((151,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hillary', 'clinton', 'supporters', 'remarks', 'nominee', 'americans', 'voters']\n",
      "['clinton', 'supporters', 'hillary', 'remarks', 'americans']\n"
     ]
    }
   ],
   "source": [
    "print(most_common_words_list)\n",
    "print(lda_top_topic_words_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(3, 1), (8, 1), (13, 1), (34, 1), (59, 1), (66, 1), (151, 1)]\n",
      "[(3, 1), (8, 1), (13, 1), (34, 1), (66, 1)]\n",
      "[40, 13, 8, 7, 6]\n"
     ]
    }
   ],
   "source": [
    "print(vec_most_common_words)\n",
    "print(vec_lda_top_topic_words)\n",
    "print(word_counts_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8451542547285165\n"
     ]
    }
   ],
   "source": [
    "cs_test = (1*1 + 1*1 + 1*1 + 1*1 + 1*1 + 1*0 + 1*0)/(np.sqrt(7)*np.sqrt(5))\n",
    "print(cs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8451542547285165"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_cosine_similarity(vec_most_common_words,vec_lda_top_topic_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zip at 0x1a1f0e1190>"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zip(vec_most_common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1., 1., 0., 0.],\n",
       "       [1., 1., 1., 1., 1., 0., 0.],\n",
       "       [1., 1., 1., 1., 1., 0., 0.],\n",
       "       [1., 1., 1., 1., 1., 0., 0.],\n",
       "       [1., 1., 1., 1., 1., 0., 0.],\n",
       "       [1., 1., 1., 1., 1., 0., 0.],\n",
       "       [1., 1., 1., 1., 1., 0., 0.]])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarity(np.array([1,1,1,1,1,1,1]).reshape(-1, 1),np.array([1,1,1,1,1,0,0]).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  [('americans', 0.019133562),\n",
       "   ('clinton', 0.018184768),\n",
       "   ('republican', 0.017437408),\n",
       "   ('voters', 0.017211813),\n",
       "   ('nominee', 0.014980899),\n",
       "   ('romney', 0.014883221),\n",
       "   ('supporters', 0.013291161),\n",
       "   ('compared', 0.012091164),\n",
       "   ('candidate', 0.011424902),\n",
       "   ('disdain', 0.0114215)]),\n",
       " (1,\n",
       "  [('clinton', 0.049737256),\n",
       "   ('remarks', 0.019014427),\n",
       "   ('movement', 0.01757419),\n",
       "   ('hillary', 0.0143344095),\n",
       "   ('nominee', 0.007829909),\n",
       "   ('racist', 0.007826811),\n",
       "   ('democratic', 0.007820644),\n",
       "   ('republican', 0.007813025),\n",
       "   ('sept', 0.007812294),\n",
       "   ('xenophobic', 0.007810709)]),\n",
       " (2,\n",
       "  [('clinton', 0.05405272),\n",
       "   ('supporters', 0.039515235),\n",
       "   ('fundraiser', 0.016904987),\n",
       "   ('hillary', 0.01688976),\n",
       "   ('pence', 0.015262421),\n",
       "   ('basket', 0.014628731),\n",
       "   ('remarks', 0.013507772),\n",
       "   ('deplorables', 0.012188577),\n",
       "   ('nominee', 0.0120312),\n",
       "   ('cycle', 0.009877269)]),\n",
       " (3,\n",
       "  [('clinton', 0.033918303),\n",
       "   ('supporters', 0.010771941),\n",
       "   ('movement', 0.009299397),\n",
       "   ('voters', 0.0092990715),\n",
       "   ('speech', 0.009297491),\n",
       "   ('alt', 0.009294607),\n",
       "   ('rally', 0.009294159),\n",
       "   ('racist', 0.009294017),\n",
       "   ('deplorable', 0.009293306),\n",
       "   ('allies', 0.009291808)]),\n",
       " (4,\n",
       "  [('clinton', 0.07019014),\n",
       "   ('russian', 0.018019238),\n",
       "   ('comparison', 0.011274058),\n",
       "   ('apologize', 0.0112712495),\n",
       "   ('nobody', 0.011270577),\n",
       "   ('hillary', 0.01124164),\n",
       "   ('praise', 0.010320582),\n",
       "   ('television', 0.010108465),\n",
       "   ('americans', 0.009864425),\n",
       "   ('gestures', 0.0095027285)])]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.030706422886377\n",
      "0.5369624187023373\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(perplexity_scores))\n",
    "print(np.std(perplexity_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         abcnews.go.com\n",
       "1          aljazeera.com\n",
       "2             apnews.com\n",
       "3                bbc.com\n",
       "4          bloomberg.com\n",
       "5          breitbart.com\n",
       "6       buzzfeednews.com\n",
       "7                cbn.com\n",
       "8            cbsnews.com\n",
       "9          csmonitor.com\n",
       "10               cnn.com\n",
       "11     thedailybeast.com\n",
       "12      democracynow.org\n",
       "13         factcheck.org\n",
       "14            forbes.com\n",
       "15           foxnews.com\n",
       "16          huffpost.com\n",
       "17       motherjones.com\n",
       "18             msnbc.com\n",
       "19    nationalreview.com\n",
       "20           nbcnews.com\n",
       "21            nypost.com\n",
       "22           nytimes.com\n",
       "23           newsmax.com\n",
       "24               npr.org\n",
       "25          politico.com\n",
       "26            reason.com\n",
       "27           reuters.com\n",
       "28             salon.com\n",
       "29         spectator.org\n",
       "30       theatlantic.com\n",
       "31       theguardian.com\n",
       "32           thehill.com\n",
       "33               wsj.com\n",
       "Name: domain, dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lda_top_topic_words\n",
    "all_sides_domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load domain names from all sides media csv, write string for google search\n",
    "all_sides_with_domains = pd.read_csv('./all_sides_media_data/allsides_final_plus_others_with_domains.csv')\n",
    "\n",
    "all_sides_names = all_sides_with_domains['name']\n",
    "all_sides_domains = all_sides_with_domains['domain']\n",
    "\n",
    "all_sides_names_domains = pd.concat([all_sides_names,all_sides_domains],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>domain</th>\n",
       "      <th>google_query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABC News (Online)</td>\n",
       "      <td>abcnews.go.com</td>\n",
       "      <td>site:nytimes.com dow trading rates vaccine wsj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Al Jazeera</td>\n",
       "      <td>aljazeera.com</td>\n",
       "      <td>site:bloomberg.com dow trading rates vaccine wsj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Associated Press</td>\n",
       "      <td>apnews.com</td>\n",
       "      <td>site:reuters.com dow trading rates vaccine wsj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BBC News</td>\n",
       "      <td>bbc.com</td>\n",
       "      <td>site:wsj.com dow trading rates vaccine wsj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bloomberg</td>\n",
       "      <td>bloomberg.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Breitbart News</td>\n",
       "      <td>breitbart.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BuzzFeed News</td>\n",
       "      <td>buzzfeednews.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CBN</td>\n",
       "      <td>cbn.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CBS News</td>\n",
       "      <td>cbsnews.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Christian Science Monitor</td>\n",
       "      <td>csmonitor.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CNN (Web News)</td>\n",
       "      <td>cnn.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Daily Beast</td>\n",
       "      <td>thedailybeast.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Democracy Now</td>\n",
       "      <td>democracynow.org</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>FactCheck.org</td>\n",
       "      <td>factcheck.org</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Forbes</td>\n",
       "      <td>forbes.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Fox News (Online)</td>\n",
       "      <td>foxnews.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>HuffPost</td>\n",
       "      <td>huffpost.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Mother Jones</td>\n",
       "      <td>motherjones.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>MSNBC</td>\n",
       "      <td>msnbc.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>National Review</td>\n",
       "      <td>nationalreview.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NBC News (Online)</td>\n",
       "      <td>nbcnews.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>New York Post</td>\n",
       "      <td>nypost.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>New York Times (Online News)</td>\n",
       "      <td>nytimes.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Newsmax - News</td>\n",
       "      <td>newsmax.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NPR Online News</td>\n",
       "      <td>npr.org</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Politico</td>\n",
       "      <td>politico.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Reason</td>\n",
       "      <td>reason.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Reuters</td>\n",
       "      <td>reuters.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Salon</td>\n",
       "      <td>salon.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>The American Spectator</td>\n",
       "      <td>spectator.org</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>The Atlantic</td>\n",
       "      <td>theatlantic.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>The Guardian</td>\n",
       "      <td>theguardian.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>The Hill</td>\n",
       "      <td>thehill.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>The Wall Street Journal</td>\n",
       "      <td>wsj.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            name              domain  \\\n",
       "0              ABC News (Online)      abcnews.go.com   \n",
       "1                     Al Jazeera       aljazeera.com   \n",
       "2               Associated Press          apnews.com   \n",
       "3                       BBC News             bbc.com   \n",
       "4                      Bloomberg       bloomberg.com   \n",
       "5                 Breitbart News       breitbart.com   \n",
       "6                  BuzzFeed News    buzzfeednews.com   \n",
       "7                            CBN             cbn.com   \n",
       "8                       CBS News         cbsnews.com   \n",
       "9      Christian Science Monitor       csmonitor.com   \n",
       "10                CNN (Web News)             cnn.com   \n",
       "11                   Daily Beast   thedailybeast.com   \n",
       "12                 Democracy Now    democracynow.org   \n",
       "13                 FactCheck.org       factcheck.org   \n",
       "14                        Forbes          forbes.com   \n",
       "15             Fox News (Online)         foxnews.com   \n",
       "16                      HuffPost        huffpost.com   \n",
       "17                  Mother Jones     motherjones.com   \n",
       "18                         MSNBC           msnbc.com   \n",
       "19               National Review  nationalreview.com   \n",
       "20             NBC News (Online)         nbcnews.com   \n",
       "21                 New York Post          nypost.com   \n",
       "22  New York Times (Online News)         nytimes.com   \n",
       "23                Newsmax - News         newsmax.com   \n",
       "24               NPR Online News             npr.org   \n",
       "25                      Politico        politico.com   \n",
       "26                        Reason          reason.com   \n",
       "27                       Reuters         reuters.com   \n",
       "28                         Salon           salon.com   \n",
       "29        The American Spectator       spectator.org   \n",
       "30                  The Atlantic     theatlantic.com   \n",
       "31                  The Guardian     theguardian.com   \n",
       "32                      The Hill         thehill.com   \n",
       "33       The Wall Street Journal             wsj.com   \n",
       "\n",
       "                                        google_query  \n",
       "0     site:nytimes.com dow trading rates vaccine wsj  \n",
       "1   site:bloomberg.com dow trading rates vaccine wsj  \n",
       "2     site:reuters.com dow trading rates vaccine wsj  \n",
       "3         site:wsj.com dow trading rates vaccine wsj  \n",
       "4                                                NaN  \n",
       "5                                                NaN  \n",
       "6                                                NaN  \n",
       "7                                                NaN  \n",
       "8                                                NaN  \n",
       "9                                                NaN  \n",
       "10                                               NaN  \n",
       "11                                               NaN  \n",
       "12                                               NaN  \n",
       "13                                               NaN  \n",
       "14                                               NaN  \n",
       "15                                               NaN  \n",
       "16                                               NaN  \n",
       "17                                               NaN  \n",
       "18                                               NaN  \n",
       "19                                               NaN  \n",
       "20                                               NaN  \n",
       "21                                               NaN  \n",
       "22                                               NaN  \n",
       "23                                               NaN  \n",
       "24                                               NaN  \n",
       "25                                               NaN  \n",
       "26                                               NaN  \n",
       "27                                               NaN  \n",
       "28                                               NaN  \n",
       "29                                               NaN  \n",
       "30                                               NaN  \n",
       "31                                               NaN  \n",
       "32                                               NaN  \n",
       "33                                               NaN  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sides_names_domains"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
